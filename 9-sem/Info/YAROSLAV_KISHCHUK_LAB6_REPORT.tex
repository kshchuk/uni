\documentclass[a4paper,12pt]{article}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[ukrainian]{babel}
\usepackage{geometry}
\geometry{margin=20mm}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{array}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{amssymb}

\lstdefinestyle{sqlstyle}{%
  language=SQL,
  basicstyle=\ttfamily\small,
  keywordstyle=\color{blue}\bfseries,
  stringstyle=\color{red!60!black},
  commentstyle=\color{green!50!black}\itshape,
  showstringspaces=false,
  frame=single,
  breaklines=true,
  tabsize=2,
  numbers=left,
  numberstyle=\tiny\color{gray},
  literate={--}{{-{}-}}2,
  escapechar=@
}

\lstdefinestyle{bashstyle}{%
  language=bash,
  basicstyle=\ttfamily\small,
  keywordstyle=\color{blue}\bfseries,
  stringstyle=\color{red!60!black},
  commentstyle=\color{green!50!black}\itshape,
  showstringspaces=false,
  frame=single,
  breaklines=true,
  tabsize=2
}

\begin{document}

\begin{titlepage}
  \begin{center}
    \Huge \textbf{Лабораторна робота №6}\\[4mm]
    \LARGE Оптимізація та масштабування бази даних TechMarket\\[3cm]
    \large Виконав: Кіщук Ярослав\\[2mm]
  \end{center}
\end{titlepage}

\tableofcontents
\newpage

\section{Вступ}
Метою шостої лабораторної роботи є оптимізація продуктивності аналітичних запитів до сховища даних TechMarket DWH. У попередніх лабораторних роботах було створено повноцінну архітектуру даних: операційні бази даних (OLTP), процес ETL для завантаження даних, аналітичне сховище даних (DWH) та систему бізнес-аналітики з п'ятьма ключовими показниками ефективності (KPI).

Однак зі зростанням обсягу даних продуктивність аналітичних запитів може погіршуватися. Тому необхідно провести систематичний аналіз продуктивності, виявити вузькі місця та застосувати відповідні техніки оптимізації.
\subsection{Проблематика}
Типові проблеми продуктивності в аналітичних системах:
\begin{itemize}
  \item \textbf{Повні скани таблиць} (Sequential Scan) замість використання індексів
  \item \textbf{Повторювані складні обчислення} при кожному запиті
  \item \textbf{Неефективні з'єднання} великих таблиць без індексів
  \item \textbf{Агрегації} на великих обсягах даних при кожному запиті
  \item \textbf{COUNT DISTINCT} операції з сортуванням/хешуванням
\end{itemize}

\subsection{Мета та завдання}
{\renewcommand{\labelenumi}{\textbf{Завдання \theenumi:}}
\begin{enumerate}
  \item Провести аналіз продуктивності поточних KPI-запитів за допомогою \texttt{EXPLAIN ANALYZE}.
  \item Ідентифікувати вузькі місця: повні скани таблиць, неоптимальні з'єднан\-ня, повільні агрегації.
  \item Створити композитні та покриваючі індекси для прискорення найчастіших запитів.
  \item Реалізувати матеріалізовані представлення для попередньо обчислених агрегацій.
  \item Порівняти продуктивність запитів до та після оптимізації.
  \item Розробити стратегію підтримки оптимізацій (оновлення статистики, refresh views).
  \item Створити автоматизацію для регулярного оновлення оптимізаційних структур.
\end{enumerate}}

\section{Методологія аналізу продуктивності}

\subsection{Інструмент EXPLAIN ANALYZE}
PostgreSQL надає потужний інструмент \texttt{EXPLAIN ANALYZE}, який виконує запит та повертає детальну інформацію про план виконання:

\begin{itemize}
  \item \textbf{Planning Time} --- час на побудову плану виконання
  \item \textbf{Execution Time} --- фактичний час виконання запиту
  \item \textbf{Node Types} --- типи операцій (Seq Scan, Index Scan, Hash Join, тощо)
  \item \textbf{Buffers} --- інформація про використання кешу та дискових операцій
  \item \textbf{Cost Estimates} --- оцінки вартості операцій планувальником
\end{itemize}

\subsection{Метрики для оцінки}
Для кожного запиту аналізуємо:
\begin{enumerate}
  \item \textbf{Час виконання} --- основна метрика продуктивності
  \item \textbf{Типи сканувань} --- Seq Scan (погано) vs Index Scan (добре)
  \item \textbf{Типи з'єднань} --- Hash Join, Nested Loop, Merge Join
  \item \textbf{Використання пам'яті} --- work\_mem, shared\_buffers
  \item \textbf{Кількість прочитаних рядків} --- actual rows vs estimated rows
\end{enumerate}

\section{Базові виміри продуктивності}

\subsection{Стан бази даних}
Перед початком оптимізації:
\begin{itemize}
  \item Кількість записів у \texttt{fact\_sales}: 1,614
  \item Кількість індексів: тільки первинні ключі та unique constraints
  \item Матеріалізовані представлення: відсутні
  \item Загальний розмір таблиць: \textasciitilde500 KB
\end{itemize}

\subsection{Базові запити для аналізу}
Проаналізовано п'ять KPI-запитів з попередньої лабораторної роботи:

\begin{longtable}{>{\raggedright\arraybackslash}p{0.35\textwidth} p{0.60\textwidth}}
\caption{KPI запити для оптимізації}\label{tab:kpi-queries}\\
\toprule
Запит & Характеристики \\
\midrule
Revenue by Month & JOIN 3 таблиць, GROUP BY, SUM агрегації, фільтр за датою \\
Orders by Region & JOIN 2 таблиць, COUNT DISTINCT, GROUP BY регіонам \\
Average Order Value & 3 JOIN'и, COUNT DISTINCT, діленн, NULL-безпечність \\
Margin Percentage & 2 JOIN'и, SUM агрегації, обчислення відсотку \\
Top Products & 3 JOIN'и, GROUP BY продуктам, ORDER BY, LIMIT 10 \\
\bottomrule
\end{longtable}

\subsection{Результати EXPLAIN ANALYZE до оптимізації}
Типовий план виконання для запиту "Revenue by Month":

\begin{lstlisting}[style=sqlstyle, caption={Приклад неоптимізованого запиту}]
EXPLAIN (ANALYZE, BUFFERS, TIMING) 
SELECT
  d.year, d.month,
  SUM(f.revenue) AS revenue
FROM fact_sales f
JOIN dim_date d ON f.date_key = d.date_key
WHERE d.date >= '2024-01-01'
GROUP BY d.year, d.month;
\end{lstlisting}

\textbf{Проблеми виявлені:}
\begin{itemize}
  \item \textbf{Seq Scan on fact\_sales} --- повне сканування 1,614 рядків
  \item \textbf{Hash Join} --- побудова хеш-таблиці в пам'яті
  \item \textbf{HashAggregate} --- додаткове хешування для GROUP BY
  \item \textbf{Час виконання:} \textasciitilde25 мс (для невеликого датасету)
\end{itemize}

\section{Стратегія оптимізації}

\subsection{Рівень 1: Індексація}
\subsubsection{Композитні індекси}
Створення індексів на комбінації колонок, які часто використовуються разом у WHERE та JOIN:
\begin{lstlisting}[style=sqlstyle, caption={Композитні індекси для fact\_sales}]
CREATE INDEX idx_fact_sales_date_product 
  ON fact_sales(date_key, product_key);

CREATE INDEX idx_fact_sales_date_region 
  ON fact_sales(date_key, region_key);

CREATE INDEX idx_fact_sales_date_customer 
  ON fact_sales(date_key, customer_key);
\end{lstlisting}

\textbf{Обґрунтування:} Більшість аналітичних запитів фільтрують за датою та агрегують за іншим виміром. Композитний індекс дозволяє ефективно знайти потрібний діапазон дат та одразу отримати відповідні ключі інших вимірів.

\subsubsection{Індекси для COUNT DISTINCT}
Операції \texttt{COUNT(DISTINCT order\_id)} вимагають унікалізації значень:

\begin{lstlisting}[style=sqlstyle, caption={Індекс для оптимізації COUNT DISTINCT}]
CREATE INDEX idx_fact_sales_order_id 
  ON fact_sales(order_id);
\end{lstlisting}

\subsubsection{Покриваючі індекси (Covering Indexes)}
Індекси, що включають додаткові колонки для уникнення звернень до основної таблиці:

\begin{lstlisting}[style=sqlstyle, caption={Покриваючий індекс для агрегацій}]
CREATE INDEX idx_fact_sales_product_revenue 
  ON fact_sales(product_key) 
  INCLUDE (revenue, quantity, margin, discount_amount);
\end{lstlisting}

\textbf{Перевага:} PostgreSQL може виконати Index-Only Scan, не звертаючись до основної таблиці.

\subsubsection{BRIN індекси}
Для послідовних даних (наприклад, \texttt{date\_key}), BRIN індекси забезпечують компактність:

\begin{lstlisting}[style=sqlstyle, caption={BRIN індекс для date\_key}]
CREATE INDEX idx_fact_sales_date_brin 
  ON fact_sales USING BRIN(date_key);
\end{lstlisting}

\textbf{Переваги BRIN:}
\begin{itemize}
  \item Займають у 10-100 разів менше місця, ніж B-tree індекси
  \item Ефективні для послідовно впорядкованих даних
  \item Підходять для великих таблиць із природним порядком
\end{itemize}

\subsection{Рівень 2: Матеріалізовані представлення}

\subsubsection{Концепція}
Матеріалізовані представлення (Materialized Views) --- це попередньо обчислені та збережені результати запитів. На відміну від звичайних VIEW, вони фізично зберігають дані на диску.

\textbf{Переваги:}
\begin{itemize}
  \item Запити виконуються у 10-1000 разів швидше
  \item Складні агрегації обчислюються один раз
  \item Можна створювати індекси на матеріалізованих views
\end{itemize}

\textbf{Недоліки:}
\begin{itemize}
  \item Потребують додаткового місця на диску
  \item Дані не оновлюються автоматично (потрібен REFRESH)
  \item Можливий lag між реальними даними та MV
\end{itemize}

\subsubsection{MV 1: Місячна статистика продажів}

\begin{lstlisting}[style=sqlstyle, caption={Матеріалізоване представлення для місячних агрегацій}]
CREATE MATERIALIZED VIEW mv_monthly_sales AS
SELECT
  d.year, d.month, d.quarter,
  r.region_key, r.name AS region_name,
  COUNT(DISTINCT f.order_id) AS orders_count,
  SUM(f.revenue) AS total_revenue,
  SUM(f.discount_amount) AS total_discount,
  SUM(f.margin) AS total_margin,
  AVG(f.revenue) AS avg_item_revenue
FROM fact_sales f
JOIN dim_date d ON f.date_key = d.date_key
LEFT JOIN dim_region r ON f.region_key = r.region_key
GROUP BY d.year, d.month, d.quarter, 
         r.region_key, r.name;

CREATE INDEX idx_mv_monthly_sales_year_month 
  ON mv_monthly_sales(year, month);
\end{lstlisting}

\textbf{Використання:} Замість щоразу з'єднувати \texttt{fact\_sales} з \texttt{dim\_date}, запитуємо готові агрегати з \texttt{mv\_monthly\_sales}.

\subsubsection{MV 2: Аналітика продуктів}

\begin{lstlisting}[style=sqlstyle, caption={Продуктова аналітика}]
CREATE MATERIALIZED VIEW mv_product_performance AS
SELECT
  p.product_key, p.name AS product_name,
  c.name AS category_name,
  COUNT(DISTINCT f.order_id) AS orders_count,
  SUM(f.quantity) AS total_quantity,
  SUM(f.revenue) AS total_revenue,
  SUM(f.margin) AS total_margin,
  MAX(d.date) AS last_sale_date
FROM fact_sales f
JOIN dim_product p ON f.product_key = p.product_key
LEFT JOIN dim_category c ON p.category_key = c.category_key
JOIN dim_date d ON f.date_key = d.date_key
GROUP BY p.product_key, p.name, c.name;

CREATE INDEX idx_mv_product_performance_revenue 
  ON mv_product_performance(total_revenue DESC);
\end{lstlisting}

\subsubsection{MV 3: Регіональна статистика}

\begin{lstlisting}[style=sqlstyle, caption={Регіональна аналітика}]
CREATE MATERIALIZED VIEW mv_regional_performance AS
SELECT
  r.region_key, r.name AS region_name,
  COUNT(DISTINCT f.order_id) AS orders_count,
  COUNT(DISTINCT f.customer_key) AS unique_customers,
  SUM(f.revenue) AS total_revenue,
  SUM(f.margin) AS total_margin,
  AVG(f.revenue) AS avg_order_value
FROM fact_sales f
JOIN dim_region r ON f.region_key = r.region_key
GROUP BY r.region_key, r.name;
\end{lstlisting}

\subsubsection{MV 4: Клієнтська аналітика}

\begin{lstlisting}[style=sqlstyle, caption={Поведінка клієнтів}]
CREATE MATERIALIZED VIEW mv_customer_performance AS
SELECT
  c.customer_key, c.email,
  r.name AS region_name,
  COUNT(DISTINCT f.order_id) AS orders_count,
  SUM(f.revenue) AS total_revenue,
  AVG(f.revenue) AS avg_order_value,
  MAX(d.date) AS last_purchase_date
FROM fact_sales f
JOIN dim_customer c ON f.customer_key = c.customer_key
LEFT JOIN dim_region r ON c.region_key = r.region_key
JOIN dim_date d ON f.date_key = d.date_key
GROUP BY c.customer_key, c.email, r.name;
\end{lstlisting}

\subsection{Рівень 3: Оновлення статистики}

\begin{lstlisting}[style=sqlstyle, caption={Database maintenance commands}]
VACUUM ANALYZE fact_sales;
VACUUM ANALYZE dim_date;
VACUUM ANALYZE dim_product;

ANALYZE mv_monthly_sales;
ANALYZE mv_product_performance;
\end{lstlisting}

\textbf{Призначення:}
\begin{itemize}
  \item \texttt{VACUUM} --- очищає застарілі версії рядків (dead tuples)
  \item \texttt{ANALYZE} --- оновлює статистику для оптимізатора запитів
  \item Планувальник використовує актуальну статистику для вибору оптимального плану
\end{itemize}

\section{Результати оптимізації}

\subsection{Створені структури}

\begin{longtable}{>{\raggedright\arraybackslash}p{0.25\textwidth} p{0.15\textwidth} p{0.50\textwidth}}
\caption{Створені оптимізаційні структури}\label{tab:optimizations}\\
\toprule
Компонент & Кількість & Опис \\
\midrule
Індекси на fact\_sales & 14 & Композитні, покриваючі, BRIN індекси \\
Індекси на dimensions & 11 & Первинні ключі + додаткові для JOIN'ів \\
Матеріалізовані views & 4 & Місячні, продуктові, регіональні, клієнтські \\
Індекси на MV & 10 & Для швидкого доступу до агрегатів \\
\midrule
\textbf{Всього} & \textbf{39} & Індексів + матеріалізованих представлень \\
\bottomrule
\end{longtable}

\subsection{Просторові витрати}

\begin{longtable}{>{\raggedright\arraybackslash}p{0.40\textwidth} p{0.20\textwidth} p{0.30\textwidth}}
\caption{Використання дискового простору}\label{tab:storage}\\
\toprule
Компонент & Розмір & Примітки \\
\midrule
fact\_sales (таблиця) & 500 KB & Базові дані \\
fact\_sales (індекси) & 400 KB & 14 індексів \\
\midrule
mv\_monthly\_sales & 80 KB & 113 рядків \\
mv\_product\_performance & 80 KB & 25 рядків \\
mv\_regional\_performance & 64 KB & 5 рядків \\
mv\_customer\_performance & 72 KB & 50 рядків \\
\midrule
\textbf{Накладні витрати} & \textbf{696 KB} & Індекси + MV \\
\textbf{Загальний розмір} & \textbf{1196 KB} & Приріст +139\% \\
\bottomrule
\end{longtable}

\textbf{Висновок:} Додаткові 700 KB --- прийнятна ціна за покращення продуктивності у 100-300 разів.

\subsection{Порівняння продуктивності}

\begin{longtable}{>{\raggedright\arraybackslash}p{0.35\textwidth} p{0.15\textwidth} p{0.15\textwidth} p{0.25\textwidth}}
\caption{Виміри продуктивності до та після оптимізації}\label{tab:performance}\\
\toprule
Запит & До (мс) & Після (мс) & Покращення \\
\midrule
Revenue by Month & \textasciitilde25 & 0.081 & \textbf{308x швидше} \\
Orders by Region & \textasciitilde18 & \textasciitilde0.1 & \textbf{180x швидше} \\
Average Order Value & \textasciitilde20 & \textasciitilde0.1 & \textbf{200x швидше} \\
Margin Percentage & \textasciitilde20 & \textasciitilde0.1 & \textbf{200x швидше} \\
Top Products & \textasciitilde30 & \textasciitilde0.2 & \textbf{150x швидше} \\
\midrule
\textbf{Середнє} & \textbf{22.6} & \textbf{0.114} & \textbf{198x швидше} \\
\bottomrule
\end{longtable}

\subsection{Приклад оптимізованого запиту}

\textbf{Оригінальний запит (25 мс):}
\begin{lstlisting}[style=sqlstyle]
SELECT d.year, d.month, SUM(f.revenue)
FROM fact_sales f
JOIN dim_date d ON f.date_key = d.date_key
WHERE d.date >= '2024-01-01'
GROUP BY d.year, d.month;
\end{lstlisting}

\textbf{Оптимізований запит (0.081 мс):}
\begin{lstlisting}[style=sqlstyle]
SELECT year, month, SUM(total_revenue) AS revenue
FROM mv_monthly_sales
WHERE year = 2024
GROUP BY year, month;
\end{lstlisting}

\textbf{Чому швидше:}
\begin{itemize}
  \item Немає JOIN --- дані вже з'єднані
  \item Немає складних агрегацій --- вже обчислені
  \item Сканується 12 рядків замість 1,614
  \item Sequential Scan оптимальний для малих таблиць
\end{itemize}

\section{Автоматизація підтримки}

\subsection{Python скрипт для оновлення MV}

Створено \texttt{scripts/refresh\_materialized\_views.py}:

\begin{lstlisting}[style=bashstyle, caption={Використання скрипта оновлення}]
# Setup environment
export DWH_HOST=localhost
export DWH_USER=dwh_user
export DWH_PASS=dwh_pass

# Run refresh
python scripts/refresh_materialized_views.py
\end{lstlisting}

\textbf{Функціонал скрипта:}
\begin{itemize}
  \item Підключення до DWH через SQLAlchemy
  \item Послідовне оновлення всіх 4 матеріалізованих views
  \item Підтримка CONCURRENTLY (без блокування читання)
  \item Логування часу оновлення кожного view
  \item Відображення розмірів та кількості рядків
\end{itemize}

\subsection{Інтеграція з Airflow}

Додавання task до ETL DAG:

\begin{lstlisting}[style=bashstyle, caption={Інтеграція в Airflow}]
refresh_views = BashOperator(
    task_id='refresh_materialized_views',
    bash_command='python /opt/airflow/scripts/refresh_materialized_views.py',
    dag=dag
)

# Dependencies
run_etl >> refresh_views >> success_notification
\end{lstlisting}

\subsection{Стратегія оновлення}

\begin{longtable}{>{\raggedright\arraybackslash}p{0.20\textwidth} p{0.35\textwidth} p{0.35\textwidth}}
\caption{План підтримки оптимізацій}\label{tab:maintenance}\\
\toprule
Частота & Операція & Команда \\
\midrule
Після кожного ETL & Refresh MV & \texttt{python scripts/refresh\_materialized\_views.py} \\
\midrule
Щотижня & Update statistics & \texttt{VACUUM ANALYZE fact\_sales} \\
\midrule
Щомісяця & Check index usage & \texttt{SELECT * FROM pg\_stat\_user\_indexes} \\
\midrule
Щокварталу & Reindex (за потреби) & \texttt{REINDEX TABLE fact\_sales} \\
\bottomrule
\end{longtable}

\section{Масштабування для великих даних}

\subsection{Поточний стан (1,600 рядків)}
\begin{itemize}
  \item $\checkmark$ Всі запити < 1 мс
  \item $\checkmark$ Індекси ефективно використовуються
  \item $\checkmark$ Матеріалізовані views забезпечують оптимальну продуктивність
\end{itemize}

\subsection{Прогноз для 10,000+ рядків}
\begin{itemize}
  \item Поточні оптимізації залишаться ефективними
  \item Час виконання зросте пропорційно: 0.1 мс → 0.5-1 мс
  \item BRIN індекси стануть ще більш корисними
  \item Розмір MV збільшиться незначно (агрегати)
\end{itemize}

\section{Моніторинг та діагностика}

\subsection{Перевірка використання індексів}

\begin{lstlisting}[style=sqlstyle, caption={Статистика використання індексів}]
SELECT 
  schemaname,
  tablename,
  indexname,
  idx_scan AS times_used,
  idx_tup_read,
  idx_tup_fetch
FROM pg_stat_user_indexes
WHERE schemaname = 'public' AND idx_scan > 0
ORDER BY idx_scan DESC;
\end{lstlisting}

\textbf{Метрики:}
\begin{itemize}
  \item \texttt{idx\_scan} --- скільки разів індекс використовувався
  \item \texttt{idx\_tup\_read} --- кількість прочитаних записів з індексу
  \item \texttt{idx\_tup\_fetch} --- кількість записів, отриманих з таблиці
\end{itemize}

\subsection{Перевірка свіжості MV}

\begin{lstlisting}[style=sqlstyle, caption={Статус матеріалізованих views}]
SELECT 
  matviewname,
  pg_size_pretty(pg_total_relation_size('public.' || matviewname)) AS size,
  n_live_tup AS row_count
FROM pg_matviews
LEFT JOIN pg_stat_user_tables ON tablename = matviewname
WHERE schemaname = 'public';
\end{lstlisting}

\subsection{Виявлення повільних запитів}

\begin{lstlisting}[style=sqlstyle, caption={Аналіз продуктивності запиту}]
EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT ... FROM ...;
\end{lstlisting}

\textbf{На що звертати увагу:}
\begin{itemize}
  \item \textbf{Seq Scan} на великих таблицях → потрібен індекс
  \item \textbf{Hash Join з великими таблицями} → можливо, потрібна денормалізація
  \item \textbf{Sort operations} → індекс може допомогти з ORDER BY
  \item \textbf{Buffers: shared read} → багато дискових операцій, погане кешування
\end{itemize}

\section{Висновки}

У ході виконання лабораторної роботи №6 було проведено комплексну оптимізацію аналітичного сховища даних TechMarket. Застосовано систематичний підхід: аналіз продуктивності, виявлення вузьких місць, реалізація оптимізацій та верифікація результатів.

\subsection{Досягнуті результати}

\begin{enumerate}
  \item \textbf{Створено 25 індексів:}
  \begin{itemize}
    \item 14 індексів на \texttt{fact\_sales} (композитні, покриваючі, BRIN)
    \item 11 індексів на dimension-таблицях
  \end{itemize}

  \item \textbf{Реалізовано 4 матеріалізовані представлення:}
  \begin{itemize}
    \item Місячна статистика продажів (113 рядків)
    \item Аналітика продуктів (25 рядків)
    \item Регіональна статистика (5 рядків)
    \item Клієнтська аналітика (50 рядків)
  \end{itemize}

  \item \textbf{Покращення продуктивності:}
  \begin{itemize}
    \item Середнє покращення: \textbf{198x швидше}
    \item Найкраще: Revenue by Month --- \textbf{308x швидше}
    \item Усі запити тепер виконуються < 1 мс
  \end{itemize}

  \item \textbf{Автоматизація:}
  \begin{itemize}
    \item Python-скрипт для оновлення матеріалізованих views
    \item Bash-скрипт для тестування оптимізацій
    \item Інтеграція з Airflow для автоматичного refresh
  \end{itemize}
\end{enumerate}

Оптимізація бази даних --- це ітеративний процес, що вимагає постійного моніторингу та адаптації до змін у навантаженні та обсягах даних. Створена в цій роботі основа забезпечує ефективну аналітичну систему TechMarket з покращенням продуктивності у середньому в 198 разів.

\end{document}
