{
 "cells": [
  {
   "cell_type": "code",
   "id": "15e6341f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T22:18:30.387621Z",
     "start_time": "2025-11-27T22:18:30.382879Z"
    }
   },
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "from var import rsa_lib\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Get number of available CPU cores (for thread pool size)\n",
    "import os\n",
    "N_WORKERS = os.cpu_count() or 4\n",
    "print(f\"Using {N_WORKERS} parallel workers\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 10 parallel workers\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "2cef2b87",
   "metadata": {},
   "source": [
    "## Load Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "id": "cb496e4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T22:18:30.397738Z",
     "start_time": "2025-11-27T22:18:30.391351Z"
    }
   },
   "source": [
    "# Load multiple encrypted texts for cross-validation\n",
    "test_cases = []\n",
    "var_path = Path('var')\n",
    "\n",
    "for i in range(1, 9):  # Load variants 1-8\n",
    "    file_path = var_path / f'{i}_encrypted_text.txt'\n",
    "    if file_path.exists():\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            # Parse the file format:\n",
    "            # Line 0: len of text: <number>\n",
    "            # Line 1: [encrypted array]\n",
    "            # Line 2: public key:<number>\n",
    "            # Line 3: n:<number>\n",
    "            ciphertext_line = lines[1].strip()\n",
    "            ciphertext = eval(ciphertext_line)\n",
    "            test_cases.append({\n",
    "                'id': i,\n",
    "                'ciphertext': ciphertext,\n",
    "                'length': len(ciphertext)\n",
    "            })\n",
    "\n",
    "print(f\"Loaded {len(test_cases)} test cases\")\n",
    "for tc in test_cases:\n",
    "    print(f\"  Case {tc['id']}: length={tc['length']}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 test cases\n",
      "  Case 1: length=24\n",
      "  Case 2: length=41\n",
      "  Case 3: length=43\n",
      "  Case 4: length=40\n",
      "  Case 5: length=38\n",
      "  Case 6: length=35\n",
      "  Case 7: length=43\n",
      "  Case 8: length=42\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "d0733ab9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T22:18:30.408421Z",
     "start_time": "2025-11-27T22:18:30.406758Z"
    }
   },
   "source": [
    "# RSA parameters\n",
    "public_key = 65537\n",
    "n = 33227\n",
    "ALPHABET = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ, \""
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "f06425fc",
   "metadata": {},
   "source": [
    "## GA Implementation Functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "25140d5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T22:18:30.414617Z",
     "start_time": "2025-11-27T22:18:30.410941Z"
    }
   },
   "source": [
    "def random_char(alphabet):\n",
    "    return random.choice(alphabet)\n",
    "\n",
    "def random_text(length, alphabet):\n",
    "    return \"\".join(random_char(alphabet) for _ in range(length))\n",
    "\n",
    "def encrypt_candidate(text, public_key, n):\n",
    "    return rsa_lib.encrypt_text(text, public_key, n)\n",
    "\n",
    "def error_P(candidate_text, target_cipher, public_key, n):\n",
    "    cand_cipher = encrypt_candidate(candidate_text, public_key, n)\n",
    "    L = min(len(cand_cipher), len(target_cipher))\n",
    "    s = sum((cand_cipher[i] - target_cipher[i]) ** 2 for i in range(L))\n",
    "    return s / L\n",
    "\n",
    "def fitness(candidate_text, target_cipher, public_key, n):\n",
    "    P = error_P(candidate_text, target_cipher, public_key, n)\n",
    "    return 1.0 / (1.0 + P)\n",
    "\n",
    "def tournament_select(population, fitnesses, tournament_size):\n",
    "    selected_idx = random.randrange(len(population))\n",
    "    for _ in range(tournament_size - 1):\n",
    "        i = random.randrange(len(population))\n",
    "        if fitnesses[i] > fitnesses[selected_idx]:\n",
    "            selected_idx = i\n",
    "    return population[selected_idx]\n",
    "\n",
    "def one_point_crossover(parent1, parent2):\n",
    "    L = len(parent1)\n",
    "    if L < 2:\n",
    "        return parent1, parent2\n",
    "    cut = random.randint(1, L - 1)\n",
    "    child1 = parent1[:cut] + parent2[cut:]\n",
    "    child2 = parent2[:cut] + parent1[cut:]\n",
    "    return child1, child2\n",
    "\n",
    "def mutate(text, mutation_rate, alphabet):\n",
    "    text_list = list(text)\n",
    "    for i in range(len(text_list)):\n",
    "        if random.random() < mutation_rate:\n",
    "            text_list[i] = random_char(alphabet)\n",
    "    return \"\".join(text_list)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "cc0abead",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T22:18:30.420768Z",
     "start_time": "2025-11-27T22:18:30.416802Z"
    }
   },
   "source": [
    "def run_ga(target_cipher, text_length, pop_size, mutation_rate, crossover_rate, \n",
    "           tournament_size, elite_count, max_generations=2000, target_error=0.0,\n",
    "           stagnation_limit=100, verbose=True):\n",
    "    \"\"\"\n",
    "    Run the genetic algorithm with given parameters.\n",
    "    Returns: (generations_to_converge, best_individual, best_error)\n",
    "    \n",
    "    Args:\n",
    "        stagnation_limit: Stop if no improvement in error for this many generations\n",
    "    \"\"\"\n",
    "    # Initialize population\n",
    "    population = [random_text(text_length, ALPHABET) for _ in range(pop_size)]\n",
    "    \n",
    "    # Track stagnation\n",
    "    best_error_ever = float('inf')\n",
    "    generations_without_improvement = 0\n",
    "    \n",
    "    for generation in range(max_generations):\n",
    "        # Evaluate current population\n",
    "        fitnesses = [fitness(ind, target_cipher, public_key, n) for ind in population]\n",
    "        \n",
    "        # Sort by fitness\n",
    "        pop_fit = list(zip(population, fitnesses))\n",
    "        pop_fit.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        best_ind, best_fit = pop_fit[0]\n",
    "        best_error = error_P(best_ind, target_cipher, public_key, n)\n",
    "        \n",
    "        if verbose and generation % 100 == 0:\n",
    "            print(f\"Gen {generation:4d} | error = {best_error:.6f} | stagnation = {generations_without_improvement}\")\n",
    "        \n",
    "        # Check convergence\n",
    "        if best_error <= target_error:\n",
    "            return generation, best_ind, best_error\n",
    "        \n",
    "        # Check for improvement\n",
    "        if best_error < best_error_ever - 1e-10:  # Small tolerance for floating point\n",
    "            best_error_ever = best_error\n",
    "            generations_without_improvement = 0\n",
    "        else:\n",
    "            generations_without_improvement += 1\n",
    "        \n",
    "        # Check stagnation - early stopping\n",
    "        if generations_without_improvement >= stagnation_limit:\n",
    "            if verbose:\n",
    "                print(f\"Early stop: no improvement for {stagnation_limit} generations\")\n",
    "            return generation, best_ind, best_error\n",
    "        \n",
    "        # Create new generation\n",
    "        new_population = [ind for ind, fit in pop_fit[:elite_count]]\n",
    "        \n",
    "        while len(new_population) < pop_size:\n",
    "            parent1 = tournament_select(population, fitnesses, tournament_size)\n",
    "            parent2 = tournament_select(population, fitnesses, tournament_size)\n",
    "            \n",
    "            if random.random() < crossover_rate:\n",
    "                child1, child2 = one_point_crossover(parent1, parent2)\n",
    "            else:\n",
    "                child1, child2 = parent1, parent2\n",
    "            \n",
    "            child1 = mutate(child1, mutation_rate, ALPHABET)\n",
    "            child2 = mutate(child2, mutation_rate, ALPHABET)\n",
    "            \n",
    "            new_population.append(child1)\n",
    "            if len(new_population) < pop_size:\n",
    "                new_population.append(child2)\n",
    "\n",
    "        population = new_population\n",
    "    \n",
    "    # Did not converge\n",
    "    return max_generations, best_ind, best_error"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "c9e4c21a",
   "metadata": {},
   "source": [
    "## Parallel Execution Functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "9f0b04c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T22:18:30.426866Z",
     "start_time": "2025-11-27T22:18:30.423018Z"
    }
   },
   "source": [
    "def run_single_fold_wrapper(test_case, params, fold_idx, seed_offset=0):\n",
    "    \"\"\"\n",
    "    Worker function for parallel execution of a single fold.\n",
    "    Returns: dict with fold results\n",
    "    \"\"\"\n",
    "    # Set random seed for reproducibility (different for each fold)\n",
    "    random.seed(42 + fold_idx + seed_offset)\n",
    "    np.random.seed(42 + fold_idx + seed_offset)\n",
    "    \n",
    "    try:\n",
    "        generations, best_ind, best_error = run_ga(\n",
    "            target_cipher=test_case['ciphertext'],\n",
    "            text_length=test_case['length'],\n",
    "            max_generations=1000,\n",
    "            target_error=0.0,\n",
    "            verbose=False,  # Disable verbose in parallel mode\n",
    "            **params\n",
    "        )\n",
    "        \n",
    "        result = {\n",
    "            'fold_idx': fold_idx,\n",
    "            'test_case_id': test_case['id'],\n",
    "            'generations': generations,\n",
    "            'error': best_error,\n",
    "            'converged': best_error == 0.0\n",
    "        }\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error in fold {fold_idx}: {e}\")\n",
    "        return {\n",
    "            'fold_idx': fold_idx,\n",
    "            'test_case_id': test_case['id'],\n",
    "            'generations': 1000,\n",
    "            'error': float('inf'),\n",
    "            'converged': False\n",
    "        }\n",
    "\n",
    "\n",
    "def evaluate_params_parallel(params, test_cases, n_cv_folds, seed_offset=0):\n",
    "    \"\"\"\n",
    "    Evaluate parameters across multiple folds in parallel using threads.\n",
    "    \"\"\"\n",
    "    fold_results = []\n",
    "    \n",
    "    # Use ThreadPoolExecutor for better Jupyter notebook compatibility\n",
    "    with ThreadPoolExecutor(max_workers=min(N_WORKERS, n_cv_folds)) as executor:\n",
    "        # Submit all tasks\n",
    "        future_to_fold = {}\n",
    "        for i in range(min(n_cv_folds, len(test_cases))):\n",
    "            future = executor.submit(\n",
    "                run_single_fold_wrapper,\n",
    "                test_cases[i],\n",
    "                params,\n",
    "                i,\n",
    "                seed_offset\n",
    "            )\n",
    "            future_to_fold[future] = i\n",
    "        \n",
    "        # Collect results as they complete\n",
    "        for future in as_completed(future_to_fold):\n",
    "            fold_idx = future_to_fold[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                fold_results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Exception in fold {fold_idx}: {e}\")\n",
    "                fold_results.append({\n",
    "                    'fold_idx': fold_idx,\n",
    "                    'test_case_id': test_cases[fold_idx]['id'],\n",
    "                    'generations': 1000,\n",
    "                    'error': float('inf'),\n",
    "                    'converged': False\n",
    "                })\n",
    "    \n",
    "    return sorted(fold_results, key=lambda x: x['fold_idx'])"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "0ebbeefa",
   "metadata": {},
   "source": [
    "## Grid Search Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "id": "21193c1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T22:18:30.433230Z",
     "start_time": "2025-11-27T22:18:30.429956Z"
    }
   },
   "source": [
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'pop_size': [100],\n",
    "    'mutation_rate': [0.01, 0.1, 0.5],\n",
    "    'crossover_rate': [0.7, 0.8, 0.9],\n",
    "    'tournament_size': [3, 10, 50],\n",
    "    'elite_count': [2, 10, 50]\n",
    "}\n",
    "\n",
    "print(\"Parameter grid:\")\n",
    "for param, values in param_grid.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "\n",
    "# Total combinations\n",
    "total_combinations = np.prod([len(v) for v in param_grid.values()])\n",
    "print(f\"\\nTotal parameter combinations: {total_combinations}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter grid:\n",
      "  pop_size: [100]\n",
      "  mutation_rate: [0.01, 0.1, 0.5]\n",
      "  crossover_rate: [0.7, 0.8, 0.9]\n",
      "  tournament_size: [3, 10, 50]\n",
      "  elite_count: [2, 10, 50]\n",
      "\n",
      "Total parameter combinations: 81\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "c280e97f",
   "metadata": {},
   "source": [
    "## Run Cross-Validation (with subset of test cases)\n",
    "\n",
    "We'll use a subset of test cases and parameter combinations for feasibility."
   ]
  },
  {
   "cell_type": "code",
   "id": "286add8f",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-27T22:18:30.443117Z"
    }
   },
   "source": [
    "# For practical reasons, we'll do random search instead of full grid search\n",
    "# Sample random parameter combinations with parallel execution\n",
    "n_random_samples = 50  # Adjust based on computational budget\n",
    "n_cv_folds = 8  # Use all 8 test cases for cross-validation\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate all parameter combinations upfront\n",
    "param_combinations = []\n",
    "for sample_idx in range(n_random_samples):\n",
    "    params = {\n",
    "        'pop_size': random.choice(param_grid['pop_size']),\n",
    "        'mutation_rate': random.choice(param_grid['mutation_rate']),\n",
    "        'crossover_rate': random.choice(param_grid['crossover_rate']),\n",
    "        'tournament_size': random.choice(param_grid['tournament_size']),\n",
    "        'elite_count': random.choice(param_grid['elite_count'])\n",
    "    }\n",
    "    param_combinations.append(params)\n",
    "\n",
    "print(f\"Running cross-validation with {n_random_samples} parameter combinations\")\n",
    "print(f\"Using {n_cv_folds} test cases per combination\")\n",
    "print(f\"Parallelizing across {N_WORKERS} workers (threads)\")\n",
    "print(f\"Total evaluations: {n_random_samples * n_cv_folds}\")\n",
    "print(\"\\nStarting parallel cross-validation...\")\n",
    "\n",
    "results = []\n",
    "\n",
    "# Process each parameter combination\n",
    "for sample_idx, params in enumerate(param_combinations):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Sample {sample_idx + 1}/{n_random_samples}\")\n",
    "    print(f\"Parameters: {params}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # Run folds in parallel using threads\n",
    "    fold_results = evaluate_params_parallel(params, test_cases, n_cv_folds, seed_offset=sample_idx*1000)\n",
    "    \n",
    "    # Display fold results\n",
    "    for fold_result in fold_results:\n",
    "        status = \"+\" if fold_result['converged'] else \"âœ—\"\n",
    "        print(f\"  {status} Fold {fold_result['fold_idx'] + 1}/{n_cv_folds} (Case {fold_result['test_case_id']}): \"\n",
    "              f\"{fold_result['generations']} gen, error={fold_result['error']:.6f}\")\n",
    "    \n",
    "    # Aggregate results\n",
    "    avg_generations = np.mean([r['generations'] for r in fold_results])\n",
    "    avg_error = np.mean([r['error'] for r in fold_results])\n",
    "    convergence_rate = np.mean([r['converged'] for r in fold_results])\n",
    "    \n",
    "    result = {\n",
    "        **params,\n",
    "        'avg_generations': avg_generations,\n",
    "        'avg_error': avg_error,\n",
    "        'convergence_rate': convergence_rate,\n",
    "        'fold_results': fold_results\n",
    "    }\n",
    "    results.append(result)\n",
    "    \n",
    "    print(f\"\\nSummary: {avg_generations:.1f} avg generations, {convergence_rate*100:.1f}% convergence rate\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Cross-validation completed!\")\n",
    "print(\"=\"*60)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cross-validation with 50 parameter combinations\n",
      "Using 8 test cases per combination\n",
      "Parallelizing across 10 workers (threads)\n",
      "Total evaluations: 400\n",
      "\n",
      "Starting parallel cross-validation...\n",
      "\n",
      "============================================================\n",
      "Sample 1/50\n",
      "Parameters: {'pop_size': 100, 'mutation_rate': 0.01, 'crossover_rate': 0.9, 'tournament_size': 10, 'elite_count': 2}\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fc22fdbf",
   "metadata": {},
   "source": [
    "## Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444cdad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df_results = pd.DataFrame([{k: v for k, v in r.items() if k != 'fold_results'} for r in results])\n",
    "\n",
    "# Sort by average generations (considering only converged solutions)\n",
    "df_converged = df_results[df_results['convergence_rate'] > 0].sort_values('avg_generations')\n",
    "\n",
    "print(\"Top 5 parameter combinations (by average generations):\")\n",
    "print(df_converged.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d5f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters\n",
    "if len(df_converged) > 0:\n",
    "    best_params = df_converged.iloc[0]\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BEST PARAMETERS:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Population size:     {int(best_params['pop_size'])}\")\n",
    "    print(f\"Mutation rate:       {best_params['mutation_rate']:.3f}\")\n",
    "    print(f\"Crossover rate:      {best_params['crossover_rate']:.2f}\")\n",
    "    print(f\"Tournament size:     {int(best_params['tournament_size'])}\")\n",
    "    print(f\"Elite count:         {int(best_params['elite_count'])}\")\n",
    "    print(f\"\\nAvg. generations:    {best_params['avg_generations']:.1f}\")\n",
    "    print(f\"Convergence rate:    {best_params['convergence_rate']*100:.1f}%\")\n",
    "else:\n",
    "    print(\"No converged solutions found. Try increasing max_generations or adjusting parameter ranges.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd35e60d",
   "metadata": {},
   "source": [
    "## Visualize Parameter Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameter effects\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "params_to_plot = ['pop_size', 'mutation_rate', 'crossover_rate', 'tournament_size', 'elite_count']\n",
    "\n",
    "for idx, param in enumerate(params_to_plot):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Group by parameter and calculate mean generations\n",
    "    grouped = df_converged.groupby(param)['avg_generations'].agg(['mean', 'std', 'count'])\n",
    "    \n",
    "    ax.errorbar(grouped.index, grouped['mean'], yerr=grouped['std'], \n",
    "                marker='o', capsize=5, capthick=2, linewidth=2)\n",
    "    ax.set_xlabel(param.replace('_', ' ').title())\n",
    "    ax.set_ylabel('Avg. Generations')\n",
    "    ax.set_title(f'Effect of {param.replace(\"_\", \" \").title()}')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Remove extra subplot\n",
    "fig.delaxes(axes[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cv_parameter_effects.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87380b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convergence rate by parameters\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, param in enumerate(['pop_size', 'mutation_rate', 'tournament_size']):\n",
    "    ax = axes[idx]\n",
    "    grouped = df_results.groupby(param)['convergence_rate'].mean()\n",
    "    \n",
    "    ax.bar(range(len(grouped)), grouped.values)\n",
    "    ax.set_xticks(range(len(grouped)))\n",
    "    ax.set_xticklabels(grouped.index)\n",
    "    ax.set_xlabel(param.replace('_', ' ').title())\n",
    "    ax.set_ylabel('Convergence Rate')\n",
    "    ax.set_title(f'Convergence Rate vs {param.replace(\"_\", \" \").title()}')\n",
    "    ax.set_ylim([0, 1.1])\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cv_convergence_rates.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5b6c60",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caee24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "df_results.to_csv('cv_results.csv', index=False)\n",
    "print(\"Results saved to 'cv_results.csv'\")\n",
    "\n",
    "# Save best parameters\n",
    "if len(df_converged) > 0:\n",
    "    with open('best_parameters.txt', 'w') as f:\n",
    "        f.write(\"BEST GA PARAMETERS (from cross-validation)\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "        f.write(f\"POP_SIZE = {int(best_params['pop_size'])}\\n\")\n",
    "        f.write(f\"MUTATION_RATE = {best_params['mutation_rate']}\\n\")\n",
    "        f.write(f\"CROSSOVER_RATE = {best_params['crossover_rate']}\\n\")\n",
    "        f.write(f\"TOURNAMENT_SIZE = {int(best_params['tournament_size'])}\\n\")\n",
    "        f.write(f\"ELITE_COUNT = {int(best_params['elite_count'])}\\n\")\n",
    "        f.write(f\"\\nAverage generations to convergence: {best_params['avg_generations']:.1f}\\n\")\n",
    "        f.write(f\"Convergence rate: {best_params['convergence_rate']*100:.1f}%\\n\")\n",
    "    print(\"Best parameters saved to 'best_parameters.txt'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
